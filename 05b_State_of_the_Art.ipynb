{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05b_State_of_the_Art.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Lp4jrmYZci",
        "colab_type": "text"
      },
      "source": [
        "# State of the Art in NLP\n",
        "\n",
        "|  | Tuesday 4-5:15pm | Friday  4-5:30pm |\n",
        "|:------:|:-------------------------------------------:|:--------------------------------------------------------------------------:|\n",
        "| **Week 1** | Introduction | Introduction |\n",
        "| **Week 2** | Custom computer vision tasks | State of the art in Computer Vision |\n",
        "| **Week 3** | Introduction to Tabular modeling and pandas | Pandas workshop and feature engineering |\n",
        "| **Week 4** | Tabular and Image Regression | Feature importance and advanced feature  engineering |\n",
        "| **Week 5** | Natural Language Processing | **State of the art in NLP** |\n",
        "| **Week 6** | Segmentation and Kaggle | Audio |\n",
        "| **Week 7** | Computer vision from scratch | NLP from scratch |\n",
        "| **Week 8** | Callbacks | Optimizers |\n",
        "| **Week 9** | Generative Adversarial Networks | Research time / presentations |\n",
        "| **Week 10** | Putting models into production | Putting models into production |\n",
        "\n",
        "Today will be run just like it was for last week, we will use the sample to run it within class time, but you should run the bottom part to see teh full extent.\n",
        "\n",
        "Topics we will be looking at:\n",
        "\n",
        "* Backwards models\n",
        "* Combining models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmiU2_kpYpGI",
        "colab_type": "text"
      },
      "source": [
        "# What is a backwards model?\n",
        "\n",
        "It does exactly as you would think. It reads the langauge backwards. Let's show a databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIQ3xEJKYxAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPRBU5hYYVQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdexf1nJg8AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path/'texts.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RJRAVilg_Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df[:800]\n",
        "df_valid = df[800:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8oE9EziY0w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm_bwd = TextLMDataBunch.from_df(path, train_df = df_train, valid_df=df_valid, backwards=True)\n",
        "data_lm_fwd = TextLMDataBunch.from_df(path, train_df = df_train, valid_df=df_valid, backwards=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txas-ajAZRMj",
        "colab_type": "code",
        "outputId": "f60ea1b6-8cb2-4636-ff05-bbe867f0da18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "data_lm_fwd.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>! ! ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . xxmaj xxunk ! xxbos xxmaj this is a extremely well - made film . xxmaj the acting , script and camera - work are all first - rate . xxmaj the music is good , too , though it is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>first loved him and then later hated him because he was xxunk . xxmaj he tries to explain to us the reasons he did what he did , but it 's really really so hard to xxunk . xxmaj such sad and unusual self destruction . xxmaj was it supposed to be funny ? xxmaj what was it all about really ? xxbos ( aka : xxup blood xxup castle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>sleeping was funny . xxmaj the xxunk bubble , and when xxmaj pumba leaves , the xxunk stop . xxmaj it 's all harmless fun , good for kids and some adults . i think this movie will last for a while because it is rather good for a straight to xxmaj video and xxup dvd movie . xxmaj while the movie does seem a little odd and kind of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>most people have said was rooting for the homeless people to make it , specially the guy , he gave me a few cheap laughs here and there . i think this film could have really been something special instead it became what every other horror nowadays are ! xxmaj just boring and well not worth the money . \\n \\n  if you are looking for a cheap scare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>xxmaj the director is unable to resist showing the destruction of a major landmark ( xxmaj big xxmaj ben ) , but at least does n't dwell xxunk on the xxunk of xxmaj london . \\n \\n  xxmaj the victory of the xxmaj martians is hardly a surprise , despite the destruction by xxunk of some of their machines . xxmaj the xxmaj narrator , traveling about to seek</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH5UBOAdZW8Y",
        "colab_type": "code",
        "outputId": "df43cbf5-f2ed-4b04-ef6a-1d3c3dc3ebf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "data_lm_bwd.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>convincing more make makeup without queens drag seen have i . completely fail they , now by guessed have will you as xxmaj . women white specific two as themselves disguise to required are brothers wayans xxmaj the however xxmaj . xxunk white to change a was script the by required was that all if enough bad be would it xxmaj . screen on put ever xxunk convincing least the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>as ( xxunk xxmaj robert xxmaj xxunk which in ) 1932 ( ' zombie xxmaj white xxmaj ' film earlier , better brothers xxunk xxmaj the from themes basic its of lot a borrows story the xxmaj . ) 1958 ( ' creole xxmaj king xxmaj ' and ) 1956 ( ' unknown xxmaj the xxmaj x ' , ) xxunk ( ' christmas xxmaj white xxmaj ' in roles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>late the in popular so became that formula horror teen stereotypical the takes , legend xxmaj urban xxmaj 's xxunk for responsible also was who , blanks xxmaj jamie xxmaj director xxmaj . horror / comedy a almost is valentine xxmaj . get to something is there but , this like film a get n't did i saying ridiculous sound might it xxmaj \\n \\n  . \" a \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>. end its toward moves it when it in quality redeeming some have does movie does enough surprisingly xxmaj xxbos . forever \" xxunk - xxunk \" of land the in lost being of consequences the suffer might she or fast , it find to needs she xxmaj . lost still is vampire xxmaj the with interview xxmaj in saw i that xxunk the , however character 's pegg xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>boy every , beautiful is melissa xxmaj since xxmaj . week one in up coming is xxunk her and old years fifteen 's she , town in girl new a is melissa xxmaj = plot xxmaj xxbos . director the sack xxmaj . better been have could xxmaj . pity xxmaj . day rainy a on entertaining - xxunk is it : general xxmaj \\n \\n  . watch to</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjJyNqCqZrou",
        "colab_type": "text"
      },
      "source": [
        "It's as simple as that! One model that goes forwards, one model that goes backwards. However this is now what Jeremy et al used to achieve state of the art results on the IMDB dataset. Now that's a lot of models to train, let's automate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-lzWIKnaINk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fwd = language_model_learner(data_lm_fwd, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
        "bwd = language_model_learner(data_lm_bwd, AWD_LSTM, drop_mult=0.3).to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Ff_QHwZpu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_models(fwd:Learner, bwd:Learner):\n",
        "  models = [fwd, bwd]\n",
        "  bs = fwd.data.batch_size\n",
        "  names = ['forward', 'backward']\n",
        "  x = 0\n",
        "  for model in models:\n",
        "    lr = 1e-2\n",
        "    lr *= bs/48\n",
        "    model.fit_one_cycle(1, lr, moms=(0.8, 0.7))\n",
        "    model.unfreeze()\n",
        "    model.fit_one_cycle(1, lr/10, moms=(0.8, 0.7))\n",
        "    model.save(f'{names[x]}_fine_tuned_10')\n",
        "    model.save_encoder(f'{names[x]}_fine_tuned_enc_10')\n",
        "    x += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj38VOwJbz4p",
        "colab_type": "text"
      },
      "source": [
        "We're going to overfit terribly here, but just remember it's a small dataset. Normally we also want to run for many more epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L0jQdl_bh6Q",
        "colab_type": "code",
        "outputId": "66f69f68-934c-4027-c283-5f0389e6989c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "train_models(fwd, bwd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.228386</td>\n",
              "      <td>3.871615</td>\n",
              "      <td>0.290223</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.755796</td>\n",
              "      <td>3.813086</td>\n",
              "      <td>0.295759</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.264483</td>\n",
              "      <td>3.918674</td>\n",
              "      <td>0.314375</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.787022</td>\n",
              "      <td>3.848752</td>\n",
              "      <td>0.321250</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ8_sttVcJm2",
        "colab_type": "text"
      },
      "source": [
        "Great! Now we have our langauge model. Let's train the classifier now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95PFIeWFblXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cls_bwd = TextClasDataBunch.from_df(path, train_df = df_train, valid_df=df_valid, backwards=True, \n",
        "                                         vocab=data_lm_bwd.vocab)\n",
        "data_cls_fwd = TextClasDataBunch.from_df(path, train_df = df_train, valid_df=df_valid, backwards=False,\n",
        "                                         vocab=data_lm_fwd.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFv1Ux4Ucd-f",
        "colab_type": "code",
        "outputId": "31dce0ec-0483-4e55-9eda-71130c0343aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "data_cls_bwd.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>\\n \\n  . grits of bowl a into hands my stick go to going 'm i , me excuse 'll you if so xxmaj ? him about film a like i can how ultimately so , him like n't do i way either xxmaj ' ? xxunk xxmaj - xxunk xxmaj xxunk my into get to want ju , bee - bay hey xxmaj ` , car his from</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>. could possibly very we that feeling it from away come we that is film this about thing best the ; film this in depicted romance the have to as lucky so be all should we xxmaj . role his in impeccable is stewart xxmaj and , charming , funny , sweet 's it xxmaj . instead christmas xxmaj this corner xxup the xxup around xxup shop xxup the xxup</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>) 10 / xxunk the about xxunk a just even know who all of hearts the break to bound is it xxmaj . costs all at avoided be to , film soderbergh xxmaj a for , shockingly -- misery irritating , confusing just is xxunk cinema interminable this of rest the xxmaj \\n \\n  . subject 's film the of execution and capture -- tragic yet -- dramatic the</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>. end xxup the xxup . other each at look they xxmaj . window the down xxunk , up drives movie the in earlier her pay n't did who contractor the xxmaj . business does normally she where corner the at xxunk and , street the down walking prostitute the see we and , off goes gun the , eventually xxmaj . aim to where her telling , mouth his</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10 / 8 . games 3d xxup of fans all to this recommended i . appeared first he after years fifteen nearly ) ? especially even maybe xxunk , recognition the deserves he ... shoes 's xxunk xxup into step and bunker the enter to door the open , xxunk xxmaj the up load so xxmaj . one this to existence their owe , genre the of rest the as</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWVSz_7ecgrM",
        "colab_type": "code",
        "outputId": "fdf6b1f1-22e6-413d-b3de-ecdad0f34b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "data_cls_fwd.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n \\n  xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , steaming bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the sweetest and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj sydney , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n \\n  xxmaj it 's usually satisfying to watch a film director change his style /</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this film sat on my xxmaj xxunk for weeks before i watched it . i dreaded a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj yorkers . \\n \\n  xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" xxmaj la xxmaj ronde</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj many neglect that this is n't just a classic due to the fact that it 's the first xxup 3d game , or even the first xxunk - up . xxmaj it 's also one of the first xxunk games , one of the xxunk definitely the first ) truly claustrophobic games , and just a pretty well - xxunk gaming experience in general . xxmaj with graphics</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-bv2QE6crBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_cls_fwd = text_classifier_learner(data_cls_fwd, AWD_LSTM, drop_mult=0.5).to_fp16()\n",
        "learn_cls_bwd = text_classifier_learner(data_cls_bwd, AWD_LSTM, drop_mult=0.5).to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMau3Pbrc431",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_cls_fwd.load_encoder('forward_fine_tuned_enc_10')\n",
        "learn_cls_bwd.load_encoder('backward_fine_tuned_enc_10')\n",
        "learn_cls_fwd.freeze()\n",
        "learn_cls_bwd.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9W7qULRcl-m",
        "colab_type": "text"
      },
      "source": [
        "Now here we are going to return our models, so we can ensemble them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhBD21packB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_models(fwd:Learner, bwd:Learner):\n",
        "  models = [fwd, bwd]\n",
        "  bs = fwd.data.batch_size\n",
        "  names = ['forward', 'backward']\n",
        "  x = 0\n",
        "  for model in models:\n",
        "    lr = 1e-2\n",
        "    lr *= bs/48\n",
        "    model.fit_one_cycle(1, lr, moms=(0.8, 0.7))\n",
        "    \n",
        "    model.freeze_to(-2)\n",
        "    model.fit_one_cycle(1, slice(lr/(2.6**4),lr), moms=(0.8,0.7))\n",
        "    \n",
        "    model.freeze_to(-3)\n",
        "    model.fit_one_cycle(1, slice(lr/2/(2.6**4),lr/2), moms=(0.8,0.7))\n",
        "    \n",
        "    model.unfreeze()\n",
        "    model.fit_one_cycle(2, slice(lr/10/(2.6**4),lr/10), moms=(0.8,0.7))\n",
        "  return fwd, bwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQbi-fLYfzT3",
        "colab_type": "code",
        "outputId": "b3bf4040-1519-4970-8748-479e2cb79c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "learn_cls_fwd, learn_cls_bwd = train_models(learn_cls_fwd, learn_cls_bwd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.583756</td>\n",
              "      <td>0.649210</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.485301</td>\n",
              "      <td>0.597441</td>\n",
              "      <td>0.635000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.393136</td>\n",
              "      <td>0.465417</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.278782</td>\n",
              "      <td>0.414369</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.247707</td>\n",
              "      <td>0.409360</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.609281</td>\n",
              "      <td>0.652833</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.576736</td>\n",
              "      <td>0.583028</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.458296</td>\n",
              "      <td>0.520996</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.386745</td>\n",
              "      <td>0.531537</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.365691</td>\n",
              "      <td>0.496964</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_t1W1ogGDv",
        "colab_type": "text"
      },
      "source": [
        "Now let's ensemble!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFA_iCtygMNW",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8u1M_Bhf5mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_a, targs_a = learn_cls_fwd.get_preds(ordered=True)\n",
        "preds_b, targs_b = learn_cls_bwd.get_preds(ordered=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXK1RDE-gdap",
        "colab_type": "code",
        "outputId": "6c717308-cdb4-49f0-8893-c01eda6ec2f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(preds_a, targs_b), accuracy(preds_b, targs_b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.8100), tensor(0.7600))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIzwENomghBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_avg = (preds_a + preds_b)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHajaPHXgul-",
        "colab_type": "code",
        "outputId": "338069bc-4ad2-4b13-b1c9-1be03d95c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(preds_avg, targs_b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyp1dMzeh2Cb",
        "colab_type": "text"
      },
      "source": [
        "See? We got some improvement!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PwXoyYcgwb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}